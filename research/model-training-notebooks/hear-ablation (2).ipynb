{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":7869025,"datasetId":4617096,"databundleVersionId":7974418}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nTB Detection Ablation Study\n============================\nExperiments:\n1. Baseline + Metadata (original approach, optimized)\n2. Cough Only (no metadata)\n3. Augmented + Metadata\n4. Augmented Only (no metadata)\n\nAll results, models, and metrics saved systematically.\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport librosa\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (recall_score, precision_score, roc_auc_score, \n                            confusion_matrix, accuracy_score, f1_score)\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nimport pickle\nimport json\nimport os\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login, from_pretrained_keras\n\ntry:\n    from xgboost import XGBClassifier\n    HAS_XGB = True\nexcept ImportError:\n    HAS_XGB = False\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\nBASE_PATH = \"/kaggle/input/tb-audio/Tuberculosis\"\nAUDIO_PATH = f\"{BASE_PATH}/raw_data/solicited_data\"\nOUTPUT_DIR = \"/kaggle/working/ablation_results\"\nCLINICAL_PATH = f\"{BASE_PATH}/metadata/CODA_TB_Clinical_Meta_Info.csv\"\nFOLDS = [(f\"{BASE_PATH}/metadata/X_train_Fold_{i}.csv\", \n          f\"{BASE_PATH}/metadata/X_test_Fold_{i}.csv\") for i in range(3)]\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nEXPERIMENTS = {\n    'baseline_meta': {'use_metadata': True, 'use_augmentation': False},\n    'cough_only': {'use_metadata': False, 'use_augmentation': False},\n    'augmented_meta': {'use_metadata': True, 'use_augmentation': True},\n    'augmented_only': {'use_metadata': False, 'use_augmentation': True}\n}\n\nprint(\"=\"*80)\nprint(\"TB DETECTION - COMPREHENSIVE ABLATION STUDY\")\nprint(\"=\"*80)\nprint(f\"Output directory: {OUTPUT_DIR}\")\nprint(f\"Timestamp: {datetime.now()}\\n\")\n\n# ============================================================================\n# LOAD HeAR MODEL\n# ============================================================================\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HF_TOKEN\"))\nmodel = from_pretrained_keras(\"google/hear\")\nserving = model.signatures['serving_default']\nprint(\"✓ HeAR model loaded\\n\")\n\n# ============================================================================\n# AUDIO PROCESSING FUNCTIONS\n# ============================================================================\ndef load_audio(fname, sr=16000, target_len=32000):\n    \"\"\"Load and normalize audio file.\"\"\"\n    try:\n        fpath = os.path.join(AUDIO_PATH, fname)\n        audio, _ = librosa.load(fpath, sr=sr, mono=True)\n        \n        # Normalize\n        audio = audio / (np.max(np.abs(audio)) + 1e-8)\n        \n        # Pad or trim\n        if len(audio) < target_len:\n            audio = np.pad(audio, (0, target_len - len(audio)))\n        else:\n            audio = audio[:target_len]\n            \n        return audio\n    except Exception as e:\n        print(f\"Error loading {fname}: {e}\")\n        return None\n\ndef augment_audio(audio, sr=16000):\n    \"\"\"Apply multiple augmentations to audio for robust training.\"\"\"\n    augmented = []\n    \n    # Original\n    augmented.append(audio)\n    \n    # Time stretch (0.9x - 1.1x)\n    for rate in [0.9, 1.1]:\n        try:\n            stretched = librosa.effects.time_stretch(audio, rate=rate)\n            if len(stretched) < len(audio):\n                stretched = np.pad(stretched, (0, len(audio) - len(stretched)))\n            else:\n                stretched = stretched[:len(audio)]\n            augmented.append(stretched)\n        except:\n            pass\n    \n    # Pitch shift (-2 to +2 semitones)\n    for n_steps in [-2, 2]:\n        try:\n            shifted = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n            augmented.append(shifted)\n        except:\n            pass\n    \n    # Add noise (SNR ~20-30dB)\n    for noise_level in [0.003, 0.005]:\n        noisy = audio + noise_level * np.random.randn(len(audio))\n        augmented.append(noisy)\n    \n    # Volume scaling\n    for scale in [0.8, 1.2]:\n        scaled = audio * scale\n        scaled = np.clip(scaled, -1, 1)\n        augmented.append(scaled)\n    \n    return augmented\n\ndef extract_embeddings_batch(df, exp_name, use_augmentation=False, batch_size=32):\n    \"\"\"Extract HeAR embeddings with optional augmentation.\"\"\"\n    embeddings, labels, filenames = [], [], []\n    batch_audio, batch_label, batch_file = [], [], []\n    \n    pbar = tqdm(df.iterrows(), total=len(df), desc=f\"{exp_name}\")\n    \n    for _, row in pbar:\n        audio = load_audio(row['filename'])\n        if audio is None:\n            continue\n        \n        audio_samples = augment_audio(audio) if use_augmentation else [audio]\n        \n        for aug_audio in audio_samples:\n            batch_audio.append(aug_audio)\n            batch_label.append(row['tb_status'])\n            batch_file.append(row['filename'])\n            \n            if len(batch_audio) >= batch_size:\n                emb = serving(x=np.array(batch_audio))['output_0'].numpy()\n                embeddings.extend(emb)\n                labels.extend(batch_label)\n                filenames.extend(batch_file)\n                batch_audio, batch_label, batch_file = [], [], []\n    \n    # Process remaining\n    if batch_audio:\n        emb = serving(x=np.array(batch_audio))['output_0'].numpy()\n        embeddings.extend(emb)\n        labels.extend(batch_label)\n        filenames.extend(batch_file)\n    \n    return np.array(embeddings), np.array(labels), filenames\n\n# ============================================================================\n# CLINICAL FEATURES\n# ============================================================================\ndef extract_clinical_features(filenames, df_original, clinical_df):\n    \"\"\"Extract clinical metadata features.\"\"\"\n    file_to_participant = dict(zip(df_original['filename'], \n                                   df_original['participant']))\n    \n    # Compute medians for imputation\n    numeric_cols = clinical_df.select_dtypes(include=[np.number])\n    medians = numeric_cols.median()\n    \n    features = []\n    for fname in filenames:\n        participant_id = file_to_participant.get(fname)\n        row = clinical_df[clinical_df['participant'] == participant_id]\n        \n        if not row.empty:\n            r = row.iloc[0]\n            age = r['age'] if pd.notna(r['age']) else medians['age']\n            height = r['height'] if pd.notna(r['height']) else medians['height']\n            weight = r['weight'] if pd.notna(r['weight']) else medians['weight']\n            bmi = weight / ((height / 100) ** 2) if height > 0 else 22.0\n            heart_rate = r['heart_rate'] if pd.notna(r['heart_rate']) else medians['heart_rate']\n            temperature = r['temperature'] if pd.notna(r['temperature']) else medians['temperature']\n            sex = 1 if r['sex'] == 'Male' else 0\n            \n            # Symptom count\n            symptom_cols = ['hemoptysis', 'weight_loss', 'fever', 'night_sweats']\n            symptoms = sum([1 for col in symptom_cols if r[col] == 'Yes'])\n            \n            features.append([age, bmi, heart_rate, temperature, sex, symptoms])\n        else:\n            # Use median defaults\n            features.append([medians['age'], 22.0, medians['heart_rate'], \n                           medians['temperature'], 0, 0])\n    \n    return np.array(features)\n\ndef build_features(embeddings, filenames, df_original, clinical_df, use_metadata):\n    \"\"\"Combine embeddings with optional clinical features.\"\"\"\n    if not use_metadata:\n        return embeddings\n    \n    clinical = extract_clinical_features(filenames, df_original, clinical_df)\n    \n    # Statistical features from embeddings\n    emb_mean = embeddings.mean(axis=1, keepdims=True)\n    emb_std = embeddings.std(axis=1, keepdims=True)\n    emb_max = embeddings.max(axis=1, keepdims=True)\n    emb_min = embeddings.min(axis=1, keepdims=True)\n    emb_q25 = np.percentile(embeddings, 25, axis=1, keepdims=True)\n    emb_q75 = np.percentile(embeddings, 75, axis=1, keepdims=True)\n    \n    # Clinical interactions\n    age_bmi = clinical[:, 0:1] * clinical[:, 1:2]\n    symp_bmi = clinical[:, 5:6] * clinical[:, 1:2]\n    age_symp = clinical[:, 0:1] * clinical[:, 5:6]\n    \n    # Embedding-clinical interactions\n    mean_age = emb_mean * clinical[:, 0:1]\n    std_symp = emb_std * clinical[:, 5:6]\n    \n    return np.concatenate([\n        embeddings, clinical, emb_mean, emb_std, emb_max, emb_min, \n        emb_q25, emb_q75, age_bmi, symp_bmi, age_symp, mean_age, std_symp\n    ], axis=1)\n\n# ============================================================================\n# MODEL BUILDING\n# ============================================================================\ndef create_ensemble():\n    \"\"\"Create ensemble classifier with multiple algorithms.\"\"\"\n    rf = RandomForestClassifier(\n        n_estimators=300, max_depth=12, min_samples_split=8,\n        class_weight={0: 1, 1: 3}, random_state=42, n_jobs=-1\n    )\n    \n    gb = GradientBoostingClassifier(\n        n_estimators=200, learning_rate=0.03, max_depth=8,\n        subsample=0.85, random_state=42\n    )\n    \n    lr = LogisticRegression(\n        max_iter=1500, C=0.3, class_weight={0: 1, 1: 4},\n        solver='saga', random_state=42\n    )\n    \n    estimators = [('rf', rf), ('gb', gb), ('lr', lr)]\n    weights = [2, 2, 1]\n    \n    if HAS_XGB:\n        xgb = XGBClassifier(\n            n_estimators=200, learning_rate=0.03, max_depth=8,\n            scale_pos_weight=3, subsample=0.85, colsample_bytree=0.85,\n            use_label_encoder=False, eval_metric='logloss', \n            random_state=42, n_jobs=-1\n        )\n        estimators.append(('xgb', xgb))\n        weights.append(2)\n    \n    return VotingClassifier(estimators=estimators, voting='soft', weights=weights)\n\n# ============================================================================\n# EVALUATION METRICS\n# ============================================================================\ndef compute_metrics(y_true, y_prob, threshold=0.5):\n    \"\"\"Compute comprehensive metrics.\"\"\"\n    y_pred = (y_prob >= threshold).astype(int)\n    \n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    \n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n    \n    return {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'sensitivity': sensitivity,\n        'specificity': specificity,\n        'precision': precision,\n        'npv': npv,\n        'f1': f1_score(y_true, y_pred, zero_division=0),\n        'auc': roc_auc_score(y_true, y_prob),\n        'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)\n    }\n\ndef find_optimal_threshold(y_true, y_prob, target_sensitivity=0.90):\n    \"\"\"Find threshold that achieves target sensitivity with max specificity.\"\"\"\n    best_threshold = 0.5\n    best_specificity = 0\n    \n    for threshold in np.sort(y_prob):\n        y_pred = (y_prob >= threshold).astype(int)\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n        \n        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n        if sensitivity < target_sensitivity:\n            break\n        \n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n        if specificity > best_specificity:\n            best_specificity = specificity\n            best_threshold = threshold\n    \n    return best_threshold\n\n# ============================================================================\n# TRAINING PIPELINE\n# ============================================================================\ndef train_experiment(exp_name, config, clinical_df):\n    \"\"\"Train a single experiment configuration across all folds.\"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"EXPERIMENT: {exp_name.upper()}\")\n    print(f\"Config: {config}\")\n    print(f\"{'='*80}\\n\")\n    \n    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n    os.makedirs(exp_dir, exist_ok=True)\n    \n    all_y_true, all_y_prob = [], []\n    fold_results = []\n    \n    for fold_idx, (train_path, test_path) in enumerate(FOLDS):\n        print(f\"\\n{'─'*80}\")\n        print(f\"FOLD {fold_idx}\")\n        print(f\"{'─'*80}\")\n        \n        df_train = pd.read_csv(train_path)\n        df_test = pd.read_csv(test_path)\n        \n        # Extract embeddings\n        X_train_emb, y_train, files_train = extract_embeddings_batch(\n            df_train, f\"{exp_name}_F{fold_idx}_train\", \n            use_augmentation=config['use_augmentation']\n        )\n        \n        X_test_emb, y_test, files_test = extract_embeddings_batch(\n            df_test, f\"{exp_name}_F{fold_idx}_test\", \n            use_augmentation=False  # Never augment test data\n        )\n        \n        # Build features\n        X_train = build_features(X_train_emb, files_train, df_train, \n                                clinical_df, config['use_metadata'])\n        X_test = build_features(X_test_emb, files_test, df_test, \n                               clinical_df, config['use_metadata'])\n        \n        # Standardize\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        # Balance training data\n        smote = SMOTE(sampling_strategy=0.8, k_neighbors=5, random_state=42)\n        under = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n        resampler = ImbPipeline([('smote', smote), ('under', under)])\n        X_train_balanced, y_train_balanced = resampler.fit_resample(\n            X_train_scaled, y_train\n        )\n        \n        print(f\"Balanced: TB- = {(y_train_balanced == 0).sum()}, \"\n              f\"TB+ = {(y_train_balanced == 1).sum()}\")\n        \n        # Train model\n        clf = create_ensemble()\n        clf.fit(X_train_balanced, y_train_balanced)\n        \n        # Predict\n        y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n        \n        # Store predictions\n        all_y_true.extend(y_test)\n        all_y_prob.extend(y_prob)\n        \n        # Fold metrics\n        fold_metrics = compute_metrics(y_test, y_prob)\n        fold_results.append(fold_metrics)\n        \n        print(f\"Fold {fold_idx} AUC: {fold_metrics['auc']:.4f}\")\n        \n        # Save fold model\n        fold_model_path = os.path.join(exp_dir, f'fold_{fold_idx}_model.pkl')\n        fold_scaler_path = os.path.join(exp_dir, f'fold_{fold_idx}_scaler.pkl')\n        with open(fold_model_path, 'wb') as f:\n            pickle.dump(clf, f)\n        with open(fold_scaler_path, 'wb') as f:\n            pickle.dump(scaler, f)\n    \n    # Aggregate results\n    y_true_all = np.array(all_y_true)\n    y_prob_all = np.array(all_y_prob)\n    \n    overall_metrics = compute_metrics(y_true_all, y_prob_all)\n    \n    # Find optimal thresholds\n    thresholds = {}\n    for target_sens in [0.85, 0.90, 0.95]:\n        thresh = find_optimal_threshold(y_true_all, y_prob_all, target_sens)\n        metrics_at_thresh = compute_metrics(y_true_all, y_prob_all, thresh)\n        thresholds[f'sens_{int(target_sens*100)}'] = {\n            'threshold': float(thresh),\n            'metrics': metrics_at_thresh\n        }\n    \n    # Train final model on all data\n    print(f\"\\n{'─'*80}\")\n    print(\"Training final model on all folds...\")\n    print(f\"{'─'*80}\")\n    \n    all_train_dfs = [pd.read_csv(FOLDS[i][0]) for i in range(3)]\n    df_all_train = pd.concat(all_train_dfs, ignore_index=True)\n    \n    X_all_emb, y_all, files_all = extract_embeddings_batch(\n        df_all_train, f\"{exp_name}_final\", \n        use_augmentation=config['use_augmentation']\n    )\n    \n    X_all = build_features(X_all_emb, files_all, df_all_train, \n                          clinical_df, config['use_metadata'])\n    \n    scaler_final = StandardScaler()\n    X_all_scaled = scaler_final.fit_transform(X_all)\n    \n    smote_final = SMOTE(sampling_strategy=0.8, k_neighbors=5, random_state=42)\n    under_final = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n    resampler_final = ImbPipeline([('smote', smote_final), ('under', under_final)])\n    X_all_balanced, y_all_balanced = resampler_final.fit_resample(\n        X_all_scaled, y_all\n    )\n    \n    clf_final = create_ensemble()\n    clf_final.fit(X_all_balanced, y_all_balanced)\n    \n    # Save final model\n    final_model_path = os.path.join(exp_dir, 'final_model.pkl')\n    final_scaler_path = os.path.join(exp_dir, 'final_scaler.pkl')\n    with open(final_model_path, 'wb') as f:\n        pickle.dump(clf_final, f)\n    with open(final_scaler_path, 'wb') as f:\n        pickle.dump(scaler_final, f)\n    \n    # Save results\n    results = {\n        'experiment': exp_name,\n        'config': config,\n        'overall_metrics': overall_metrics,\n        'fold_metrics': fold_results,\n        'avg_fold_auc': float(np.mean([f['auc'] for f in fold_results])),\n        'optimal_thresholds': thresholds,\n        'timestamp': str(datetime.now())\n    }\n    \n    results_path = os.path.join(exp_dir, 'results.json')\n    with open(results_path, 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    # Print summary\n    print(f\"\\n{'='*80}\")\n    print(f\"EXPERIMENT {exp_name.upper()} - SUMMARY\")\n    print(f\"{'='*80}\")\n    print(f\"Overall AUC: {overall_metrics['auc']:.4f}\")\n    print(f\"Avg Fold AUC: {results['avg_fold_auc']:.4f}\")\n    print(f\"Sensitivity: {overall_metrics['sensitivity']:.4f}\")\n    print(f\"Specificity: {overall_metrics['specificity']:.4f}\")\n    print(f\"Precision: {overall_metrics['precision']:.4f}\")\n    print(f\"NPV: {overall_metrics['npv']:.4f}\")\n    print(f\"\\nOptimal Thresholds:\")\n    for target, data in thresholds.items():\n        m = data['metrics']\n        print(f\"  {target}: T={data['threshold']:.4f} | \"\n              f\"Sens={m['sensitivity']:.3f} | Spec={m['specificity']:.3f} | \"\n              f\"NPV={m['npv']:.3f}\")\n    print(f\"{'='*80}\\n\")\n    \n    return results\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\ndef main():\n    \"\"\"Run all ablation experiments.\"\"\"\n    clinical_df = pd.read_csv(CLINICAL_PATH)\n    \n    all_results = {}\n    \n    for exp_name, config in EXPERIMENTS.items():\n        try:\n            results = train_experiment(exp_name, config, clinical_df)\n            all_results[exp_name] = results\n        except Exception as e:\n            print(f\"\\n❌ ERROR in {exp_name}: {e}\")\n            import traceback\n            traceback.print_exc()\n            continue\n    \n    # Save comparative summary\n    summary_path = os.path.join(OUTPUT_DIR, 'ablation_summary.json')\n    with open(summary_path, 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    # Create comparison table\n    print(f\"\\n{'='*80}\")\n    print(\"ABLATION STUDY - COMPARATIVE RESULTS\")\n    print(f\"{'='*80}\\n\")\n    \n    comparison = []\n    for exp_name, results in all_results.items():\n        if 'overall_metrics' in results:\n            m = results['overall_metrics']\n            comparison.append({\n                'Experiment': exp_name,\n                'AUC': f\"{m['auc']:.4f}\",\n                'Sensitivity': f\"{m['sensitivity']:.4f}\",\n                'Specificity': f\"{m['specificity']:.4f}\",\n                'Precision': f\"{m['precision']:.4f}\",\n                'NPV': f\"{m['npv']:.4f}\",\n                'F1': f\"{m['f1']:.4f}\"\n            })\n    \n    if comparison:\n        df_comparison = pd.DataFrame(comparison)\n        print(df_comparison.to_string(index=False))\n        \n        csv_path = os.path.join(OUTPUT_DIR, 'comparison.csv')\n        df_comparison.to_csv(csv_path, index=False)\n        print(f\"\\n✓ Comparison saved to: {csv_path}\")\n    \n    print(f\"\\n{'='*80}\")\n    print(\"✅ ABLATION STUDY COMPLETE\")\n    print(f\"{'='*80}\")\n    print(f\"All results saved to: {OUTPUT_DIR}\")\n    print(f\"  - Individual experiment folders with models and scalers\")\n    print(f\"  - ablation_summary.json (comprehensive results)\")\n    print(f\"  - comparison.csv (quick comparison table)\")\n    print(f\"{'='*80}\\n\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# This lists all \"attached\" secret labels\nsecrets_list = [k for k in os.environ.keys() if 'KAGGLE_USER_SECRETS' in k]\nprint(f\"Attached secrets: {secrets_list}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T00:13:32.664056Z","iopub.execute_input":"2026-02-04T00:13:32.664393Z","iopub.status.idle":"2026-02-04T00:13:32.669337Z","shell.execute_reply.started":"2026-02-04T00:13:32.664366Z","shell.execute_reply":"2026-02-04T00:13:32.668648Z"}},"outputs":[{"name":"stdout","text":"Attached secrets: ['KAGGLE_USER_SECRETS_TOKEN']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\n# Initialize the client\nuser_secrets = UserSecretsClient()\n\n# Get the secret\ntry:\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n    print(\"Success! Token retrieved.\")\nexcept Exception as e:\n    print(f\"Still failing. Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T00:13:16.947908Z","iopub.execute_input":"2026-02-04T00:13:16.948432Z","iopub.status.idle":"2026-02-04T00:13:17.024417Z","shell.execute_reply.started":"2026-02-04T00:13:16.948409Z","shell.execute_reply":"2026-02-04T00:13:17.023685Z"}},"outputs":[{"name":"stdout","text":"Success! Token retrieved.\n","output_type":"stream"}],"execution_count":3}]}